{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using class attention for zero-shot learning\n",
    "\n",
    "Terrible zero-shot performance for now, but we have a testing setup now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import class_attention as cat\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def detorch(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classes(dataset, p_valid_classes=None, valid_classes=None, class_field_name='category', verbose=False):\n",
    "    \"\"\"\n",
    "    Move random classes to a class-validation set (i.e. meta-test).\n",
    "    \n",
    "    All dataset examples with these classes are removed from the original dataset\n",
    "\n",
    "    Args:\n",
    "        dataset: datasets.arrow_dataset.Dataset object\n",
    "        p_valid_classes: 0 < float < 1\n",
    "        valid_classes: alternative to p_valid_classes, a list of classes to move to the class-validation set\n",
    "        class_field_name: name of the class field in the dataset\n",
    "        verbose: log splitted classes info\n",
    "    \n",
    "    Returns:\n",
    "        (train_set, class_validation_set)\n",
    "        where both objects are ArrowDataset and all validation classes are moved to class_validation_set\n",
    "    \"\"\"\n",
    "    \n",
    "    if not (p_valid_classes is None) ^ (valid_classes is None):\n",
    "        raise ValueError(\"Only one of p_valid_classes or valid_classes should be specified. \"\n",
    "                         f\"Got p_valid_classes = {p_valid_classes}\\n\"\n",
    "                         f\"valid_classes = {valid_classes}\")\n",
    "\n",
    "    if p_valid_classes is not None:\n",
    "        all_classes = list(set(dataset[class_field_name]))\n",
    "        n_valid_classes = int(len(all_classes) * p_valid_classes)\n",
    "        if n_valid_classes == 0:\n",
    "            raise ValueError(f\"p_valid_classes={p_valid_classes} is too small for the dataset with {len(all_classes)} classes.\")\n",
    "\n",
    "        valid_classes = random.sample(all_classes, k=n_valid_classes)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Moving the following classes to a class-validation set: {valid_classes}\")\n",
    "    \n",
    "    valid_mask = [c in valid_classes for c in dataset[class_field_name]]\n",
    "    train_mask = [not m for m in valid_mask]\n",
    "\n",
    "    valid_subset = dataset[valid_mask]\n",
    "    train_subset = dataset[train_mask]\n",
    "    \n",
    "    valid_dataset = datasets.arrow_dataset.Dataset.from_dict(valid_subset)\n",
    "    train_dataset = datasets.arrow_dataset.Dataset.from_dict(train_subset)\n",
    "    \n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on labels\n",
    "\n",
    "The dataset we use (`Fraser/news-category-dataset`) has some interesting particularities in the class names.\n",
    "\n",
    "For example, it has classes `STYLE` and `STYLE & BEAUTY` or `WORLD NEWS` and `NEWS`. I.e., some classes contain other classes names in their name.\n",
    "The classes that have `&` in their name have a similar particularity. Some of the categories does not seem to be distinguishable. E.g., `THE WORLDPOST` and `WORLDPOST` or `ARTS & CULTURE` and `CULTURE & ARTS`.\n",
    "\n",
    "\n",
    "\n",
    "* &\t: STYLE & BEAUTY, ARTS & CULTURE, HOME & LIVING, FOOD & DRINK, CULTURE & ARTS\n",
    "* VOICES\t: LATINO VOICES, BLACK VOICES, QUEER VOICES\n",
    "* NEWS\t: WEIRD NEWS, GOOD NEWS, WORLD NEWS\n",
    "* ARTS\t: ARTS, ARTS & CULTURE, CULTURE & ARTS\n",
    "* CULTURE\t: ARTS & CULTURE, CULTURE & ARTS\n",
    "* LIVING\t: HEALTHY LIVING, HOME & LIVING\n",
    "* WORLDPOST\t: THE WORLDPOST, WORLDPOST\n",
    "* WORLD\t: THE WORLDPOST, WORLDPOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset news_category (/home/vlialin/.cache/huggingface/datasets/news_category/default/0.0.0/737b7b6dff469cbba49a6202c9e94f9d39da1fed94e13170cf7ac4b61a75fb9c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving the following classes to a class-validation set: ['EDUCATION', 'STYLE & BEAUTY', 'RELIGION', 'SCIENCE', 'PARENTING', 'ARTS & CULTURE', 'ARTS', 'DIVORCE']\n",
      "Total classes: 41\n",
      "Size of the resulting training set: 13641\n",
      "Size of the resulting validation set for the train classes: 843\n",
      "Size of the resulting validation set for the valid classes: 161\n"
     ]
    }
   ],
   "source": [
    "news_dataset = datasets.load_dataset(\"Fraser/news-category-dataset\")\n",
    "\n",
    "# some magic is happening here to make a toy dataset that is consistent, read carefuly\n",
    "train_set = cat.utils.sample_dataset(news_dataset['train'], p=0.1)\n",
    "\n",
    "all_classes = list(set(news_dataset['train']['category']))\n",
    "classes_left = list(set(train_set['category']))\n",
    "\n",
    "valid_set = news_dataset['validation']\n",
    "if len(all_classes) > len(classes_left):\n",
    "    _, valid_set = split_classes(valid_set, valid_classes=classes_left)\n",
    "\n",
    "valid_set = cat.utils.sample_dataset(valid_set, p=0.1)\n",
    "\n",
    "del news_dataset\n",
    "\n",
    "# TODO: you need to work on naming\n",
    "\n",
    "# valid_classes = ['TASTE', 'WELLNESS', 'EDUCATION']\n",
    "train_reduced_set, _train_remainder = split_classes(train_set, p_valid_classes=0.21, verbose=True)\n",
    "\n",
    "valid_classes = list(set(_train_remainder['category']))\n",
    "valid_reduced_set, valid_remainder = split_classes(valid_set, valid_classes=valid_classes)\n",
    "\n",
    "del train_set\n",
    "\n",
    "print(f\"Total classes: {len(all_classes)}\")\n",
    "print(f\"Size of the resulting training set: {len(train_reduced_set)}\")\n",
    "print(f\"Size of the resulting validation set for the train classes: {len(valid_reduced_set)}\")\n",
    "print(f\"Size of the resulting validation set for the valid classes: {len(valid_remainder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatTestCollator:\n",
    "    \"\"\"\n",
    "    Collates text into batches with a fixed set of labels.\n",
    "\n",
    "    During inference, we do not know in advance what class we have to predict.\n",
    "    Thus, using a regular CatCollator that only inputs into the model\n",
    "    a subset of classes is not possible as it would be cheating.\n",
    "\n",
    "    The set of possible classes in this collator is defined during initialization\n",
    "    and all of them are used for every batch.\n",
    "\n",
    "    Args:\n",
    "        possible_labels: torch.LongTensor[n_labels, label_len], a matrix of padded label ids\n",
    "        pad_token_id: paddng token id used for BOTH texts and labels\n",
    "    \"\"\"\n",
    "    def __init__(self, possible_labels: torch.LongTensor, pad_token_id):\n",
    "        self.possible_labels = possible_labels\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        \"\"\"\n",
    "        Collates examples into batches and creates targets for the ``contrastive loss''.\n",
    "\n",
    "        The main difference with CatCollator is the unique_labels.\n",
    "        In the case of test collator, it is always equal to self.possible_labels\n",
    "        and do not depend on the batch labels.\n",
    "\n",
    "        Args:\n",
    "            examples: list of tuples (text_seq, label_seq)\n",
    "                where\n",
    "                text_seq: LongTensor[text_len,]\n",
    "                label_seq: LongTensor[label_len,]\n",
    "\n",
    "        Returns:\n",
    "            a tuple (batch_x, unique_labels, targets)\n",
    "                where\n",
    "                batch_x: LongTensor[batch_size, max_text_len]\n",
    "                unique_labels: LongTensor[batch_size,] = self.possible_labels\n",
    "                targets: LongTensor[batch_size,]\n",
    "        \"\"\"\n",
    "        _validate_input(examples)\n",
    "\n",
    "        batch_size = len(examples)\n",
    "        max_text_len = max(len(text) for text, label in examples)\n",
    "        max_label_len = max(len(label) for label in self.possible_labels)  # 1st major difference from CatCollator\n",
    "        device = examples[0][0].device\n",
    "\n",
    "        # we construct this tensor only to use it in get_index, we do not return it\n",
    "        _pre_batch_y = torch.full(\n",
    "            size=[batch_size, max_label_len],\n",
    "            fill_value=self.pad_token_id,\n",
    "            dtype=torch.int64,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_x = torch.full(\n",
    "            size=[batch_size, max_text_len],\n",
    "            fill_value=self.pad_token_id,\n",
    "            dtype=torch.int64,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        for i, (text, label) in enumerate(examples):\n",
    "            batch_x[i, : len(text)] = text\n",
    "            \n",
    "            try:\n",
    "                _pre_batch_y[i, : len(label)] = label\n",
    "            except:\n",
    "                import pdb; pdb.set_trace()\n",
    "                print(_pre_batch_y.shape)\n",
    "                print(i)\n",
    "                print(len(label))\n",
    "                print(label.shape)\n",
    "\n",
    "        targets = get_index(self.possible_labels, _pre_batch_y)  # 2nd major difference from CatCollator\n",
    "\n",
    "        if batch_size != targets.shape[0]:\n",
    "            import pdb; pdb.set_trace()\n",
    "            raise RuntimeError(f\"Wrong number of targets. Expected {batch_size}, got {targets.shape[0]} instead.\")\n",
    "\n",
    "        return batch_x, self.possible_labels, targets\n",
    "\n",
    "\n",
    "def get_index(host, target):\n",
    "    diff = target.unsqueeze(1) - host.unsqueeze(0)\n",
    "    dsum = torch.abs(diff).sum(-1)\n",
    "    loc = torch.nonzero(dsum == 0)\n",
    "    return loc[:, -1]\n",
    "\n",
    "def _validate_input(examples):\n",
    "    if not isinstance(examples[0], tuple):\n",
    "        raise ValueError(examples)\n",
    "\n",
    "    text_0, label_0 = examples[0]\n",
    "    if not len(text_0.shape) == 1:\n",
    "        raise ValueError(\n",
    "            f\"Wrong number of dimensions in the text tensor. \"\n",
    "            f\"Expected a rank-one tensor, got rank-{len(text_0.shape)} instead\"\n",
    "        )\n",
    "\n",
    "    if not len(label_0.shape) == 1:\n",
    "        raise ValueError(\n",
    "            f\"Wrong number of dimensions in the label tensor. \"\n",
    "            f\"Expected a rank-one tensor, got rank-{len(label_0.shape)} instead\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "__all__ = [\"MaskPowerNorm\"]\n",
    "\n",
    "\n",
    "def _sum_ft(tensor):\n",
    "    \"\"\"sum over the first and last dimention\"\"\"\n",
    "    return tensor.sum(dim=0).sum(dim=-1)\n",
    "\n",
    "\n",
    "class GroupScaling1D(nn.Module):\n",
    "    r\"\"\"Scales inputs by the second moment for the entire layer.\"\"\"\n",
    "\n",
    "    def __init__(self, eps=1e-5, group_num=4):\n",
    "        super(GroupScaling1D, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.group_num = group_num\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"eps={self.eps}, group={self.group_num}\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        # calculate second moment\n",
    "        # different group use different mean\n",
    "        T, B, C = input.shape[0], input.shape[1], input.shape[2]\n",
    "        Cg = C // self.group_num\n",
    "        gn_input = input.contiguous().reshape(T, B, self.group_num, Cg)\n",
    "        moment2 = (\n",
    "            torch.repeat_interleave(\n",
    "                torch.mean(gn_input * gn_input, dim=3, keepdim=True), repeats=Cg, dim=-1\n",
    "            )\n",
    "            .contiguous()\n",
    "            .reshape(T, B, C)\n",
    "        )\n",
    "        # divide out second moment\n",
    "        return input / torch.sqrt(moment2 + self.eps)\n",
    "\n",
    "\n",
    "def _unsqueeze_ft(tensor):\n",
    "    \"\"\"add new dimensions at the front and the tail\"\"\"\n",
    "    return tensor.unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "\n",
    "class PowerFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        ctx,\n",
    "        x,\n",
    "        weight,\n",
    "        bias,\n",
    "        running_phi,\n",
    "        eps,\n",
    "        afwd,\n",
    "        abkw,\n",
    "        ema_gz,\n",
    "        debug,\n",
    "        warmup_iters,\n",
    "        current_iter,\n",
    "        mask_x,\n",
    "    ):\n",
    "        ctx.eps = eps\n",
    "        ctx.debug = debug\n",
    "        current_iter = current_iter.item()\n",
    "        ctx.current_iter = current_iter\n",
    "        ctx.warmup_iters = warmup_iters\n",
    "        ctx.abkw = abkw\n",
    "        rmax = 1\n",
    "        N, C, H, W = x.size()\n",
    "        x2 = (mask_x * mask_x).mean(dim=0)\n",
    "\n",
    "        var = x2.reshape(1, C, 1, 1)\n",
    "        if current_iter <= warmup_iters:\n",
    "            z = x / (var + eps).sqrt()\n",
    "        else:\n",
    "            z = x / (running_phi + eps).sqrt()\n",
    "\n",
    "        y = z\n",
    "        ctx.save_for_backward(z, var, weight, ema_gz)\n",
    "\n",
    "        if current_iter < warmup_iters:\n",
    "            running_phi.copy_(\n",
    "                running_phi * (current_iter - 1) / current_iter\n",
    "                + var.mean(dim=0, keepdim=True) / current_iter\n",
    "            )\n",
    "        running_phi.copy_(afwd * running_phi + (1 - afwd) * var.mean(dim=0, keepdim=True))\n",
    "        y = weight.reshape(1, C, 1, 1) * y + bias.reshape(1, C, 1, 1)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = ctx.eps\n",
    "        debug = ctx.debug\n",
    "        current_iter = ctx.current_iter\n",
    "        warmup_iters = ctx.warmup_iters\n",
    "        abkw = ctx.abkw\n",
    "\n",
    "        N, C, H, W = grad_output.size()\n",
    "        z, var, weight, ema_gz = ctx.saved_variables\n",
    "\n",
    "        y = z\n",
    "        g = grad_output * weight.reshape(1, C, 1, 1)\n",
    "        g = g * 1\n",
    "\n",
    "        gz = (g * z).mean(dim=3).mean(dim=2).mean(dim=0)\n",
    "\n",
    "        approx_grad_g = g - (1 - abkw) * ema_gz * z\n",
    "        ema_gz.add_(\n",
    "            (approx_grad_g * z)\n",
    "            .mean(dim=3, keepdim=True)\n",
    "            .mean(dim=2, keepdim=True)\n",
    "            .mean(dim=0, keepdim=True)\n",
    "        )\n",
    "\n",
    "        gx = 1.0 / torch.sqrt(var + eps) * approx_grad_g\n",
    "        return (\n",
    "            gx,\n",
    "            (grad_output * y).sum(dim=3).sum(dim=2).sum(dim=0),\n",
    "            grad_output.sum(dim=3).sum(dim=2).sum(dim=0),\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "\n",
    "class MaskPowerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    An implementation of masked batch normalization, used for testing the numerical\n",
    "    stability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        eps=1e-5,\n",
    "        alpha_fwd=0.9,\n",
    "        alpha_bkw=0.9,\n",
    "        affine=True,\n",
    "        warmup_iters=10000,\n",
    "        group_num=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        self.register_parameter(\"weight\", nn.Parameter(torch.ones(num_features)))\n",
    "        self.register_parameter(\"bias\", nn.Parameter(torch.zeros(num_features)))\n",
    "        self.register_buffer(\"running_phi\", torch.ones(1, num_features, 1, 1))\n",
    "        self.register_buffer(\"ema_gz\", torch.zeros(1, num_features, 1, 1))\n",
    "        self.register_buffer(\"iters\", torch.zeros(1).type(torch.LongTensor))\n",
    "\n",
    "        self.afwd = alpha_fwd\n",
    "        self.abkw = alpha_bkw\n",
    "\n",
    "        self.eps = eps\n",
    "        self.debug = False\n",
    "        self.warmup_iters = warmup_iters\n",
    "        self.gp = GroupScaling1D(group_num=group_num)\n",
    "        self.group_num = group_num\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (\n",
    "            \"{num_features}, eps={eps}, alpha_fwd={afwd}, alpha_bkw={abkw}, \"\n",
    "            \"affine={affine}, warmup={warmup_iters}, group_num={group_num}\".format(**self.__dict__)\n",
    "        )\n",
    "\n",
    "    def forward(self, input, pad_mask=None, is_encoder=False):\n",
    "        \"\"\"\n",
    "        input:  T x B x C -> B x C x T\n",
    "             :  B x C x T -> T x B x C\n",
    "        pad_mask: B x T (padding is True)\n",
    "        \"\"\"\n",
    "        shaped_input = len(input.shape) == 2\n",
    "        if shaped_input:\n",
    "            input = input.unsqueeze(0)\n",
    "        T, B, C = input.shape\n",
    "        input = self.gp(input)\n",
    "\n",
    "        # construct the mask_input, size to be (BxL) x C: L is the real length here\n",
    "        if pad_mask is None:\n",
    "            mask_input = input.clone()\n",
    "        else:\n",
    "            # Transpose the bn_mask (B x T -> T x B)\n",
    "            bn_mask = ~pad_mask\n",
    "            bn_mask = bn_mask.transpose(0, 1)\n",
    "\n",
    "        if pad_mask is not None:\n",
    "            pad_size = (~bn_mask).sum()\n",
    "            mask_input = input[bn_mask, :]\n",
    "        else:\n",
    "            mask_input = input.clone()\n",
    "\n",
    "        mask_input = mask_input.reshape(-1, self.num_features)\n",
    "\n",
    "        input = input.permute(1, 2, 0).contiguous()\n",
    "        input_shape = input.size()\n",
    "        input = input.reshape(input.size(0), self.num_features, -1)\n",
    "        input = input.unsqueeze(-1)\n",
    "\n",
    "        if self.training:\n",
    "            self.iters.copy_(self.iters + 1)\n",
    "            output = PowerFunction.apply(\n",
    "                input,\n",
    "                self.weight,\n",
    "                self.bias,\n",
    "                self.running_phi,\n",
    "                self.eps,\n",
    "                self.afwd,\n",
    "                self.abkw,\n",
    "                self.ema_gz,\n",
    "                self.debug,\n",
    "                self.warmup_iters,\n",
    "                self.iters,\n",
    "                mask_input,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            N, C, H, W = input.size()\n",
    "            var = self.running_phi\n",
    "            output = input / (var + self.eps).sqrt()\n",
    "            output = self.weight.reshape(1, C, 1, 1) * output + self.bias.reshape(1, C, 1, 1)\n",
    "\n",
    "        output = output.reshape(input_shape)\n",
    "        output = output.permute(2, 0, 1).contiguous()\n",
    "        # Reshape it.\n",
    "        if shaped_input:\n",
    "            output = output.squeeze(0)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from class_attention import modelling_utils\n",
    "\n",
    "\n",
    "def normalize_embeds(embeds):\n",
    "    return embeds / torch.sqrt(torch.sum(embeds * embeds, dim=1, keepdim=True))\n",
    "\n",
    "\n",
    "class ClassAttentionModel(nn.Module):\n",
    "    def __init__(self, txt_encoder, cls_encoder, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "#         print('Hidden size is not used')\n",
    "\n",
    "        self.txt_encoder = txt_encoder\n",
    "        self.cls_encoder = cls_encoder\n",
    "\n",
    "        txt_encoder_h = modelling_utils.get_output_dim(txt_encoder)\n",
    "        self.txt_out = nn.Linear(txt_encoder_h, hidden_size)\n",
    "#         self.txt_out_norm = MaskPowerNorm(hidden_size)\n",
    "\n",
    "        cls_encoder_h = modelling_utils.get_output_dim(cls_encoder)\n",
    "        self.cls_out = nn.Linear(cls_encoder_h, hidden_size)\n",
    "#         self.cls_out_norm = MaskPowerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, text_input, labels_input):\n",
    "        \"\"\"\n",
    "        Compute logits for input (input_dict,) corresponding to the classes (classes_dict)\n",
    "\n",
    "        Optionally, you can provide additional keys in either input_dict or classes_dict\n",
    "        Specifically, attention_mask, head_mask and inputs_embeds\n",
    "        Howerver, one should not provide output_attentions and output_hidden_states\n",
    "\n",
    "        Args:\n",
    "            text_input: dict with key input_ids\n",
    "                input_ids: LongTensor[batch_size, text_seq_len], input to the text network\n",
    "            labels_input: dict with key input_ids\n",
    "                input_ids: LongTensor[n_classes, class_seq_len], a list of possible classes, each class described via text\n",
    "        \"\"\"\n",
    "        text_input, labels_input = modelling_utils.maybe_format_inputs(text_input, labels_input)\n",
    "        modelling_utils.validate_inputs(text_input, labels_input)\n",
    "\n",
    "        h_x = self.txt_encoder(**text_input)  # some tuple\n",
    "        h_x = h_x[0]  # FloatTensor[bs, text_seq_len, hidden]\n",
    "        h_x = h_x[:, 0]  # get CLS token representations, FloatTensor[bs, hidden]\n",
    "\n",
    "        h_c = self.cls_encoder(**labels_input)  # some tuple\n",
    "        h_c = h_c[0]  # FloatTensor[n_classes, class_seq_len, hidden]\n",
    "\n",
    "        h_c, _ = torch.max(h_c, dim=1)  # [n_classes, hidden]\n",
    "\n",
    "        # attention map\n",
    "        h_x = self.txt_out(h_x)\n",
    "#         h_x = F.dropout(h_x, p=0.5)\n",
    "#         h_x = self.txt_out_norm(h_x)\n",
    "\n",
    "        h_c = self.cls_out(h_c)\n",
    "        h_c = normalize_embeds(h_c)\n",
    "\n",
    "#         h_c = F.dropout(h_c, p=0.5)\n",
    "#         h_c = self.txt_out_norm(h_c)\n",
    "\n",
    "        # the scaling is extremely important\n",
    "        scaling = h_c.size(-1) ** 0.5\n",
    "        logits = (h_x @ h_c.T) / scaling  # [bs, n_classes]\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3784bc990d43ff8265e4af7eee95eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing Dataset', max=13641.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf4861737484d07b5ce47f750c2db8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing Dataset', max=1004.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1bce43b9294875ae1c0d4c73c4e2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing Dataset', max=843.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3962fb9218354568835ad03da36a1efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing Dataset', max=161.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizers\n",
    "MODEL = 'distilbert-base-uncased'\n",
    "text_tokenizer = AutoTokenizer.from_pretrained(MODEL, fast=True)\n",
    "label_tokenizer = AutoTokenizer.from_pretrained(MODEL, fast=True)\n",
    "\n",
    "# Dataset\n",
    "dataset = cat.CatDataset(train_reduced_set['headline'], text_tokenizer, train_reduced_set['category'], label_tokenizer)\n",
    "valid_dataset = cat.CatDataset(valid_set['headline'], text_tokenizer, valid_set['category'], label_tokenizer)\n",
    "valid_train_dataset = cat.CatDataset(valid_reduced_set['headline'], text_tokenizer, valid_reduced_set['category'], label_tokenizer)\n",
    "valid_valid_dataset = cat.CatDataset(valid_remainder['headline'], text_tokenizer, valid_remainder['category'], label_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 20429,   102,     0,     0],\n",
       "         [  101, 25860,   102,     0,     0],\n",
       "         [  101,  2308,   102,     0,     0],\n",
       "         [  101,  2267,   102,     0,     0],\n",
       "         [  101,  2840,  1004,  3226,   102],\n",
       "         [  101,  3604,   102,     0,     0],\n",
       "         [  101,  7402,  5755,   102,     0],\n",
       "         [  101,  8179,   102,     0,     0],\n",
       "         [  101,  5595,   102,     0,     0],\n",
       "         [  101,  1996,  2088, 19894,   102],\n",
       "         [  101,  2665,   102,     0,     0],\n",
       "         [  101,  6627,   102,     0,     0],\n",
       "         [  101,  2449,   102,     0,     0],\n",
       "         [  101,  4254,   102,     0,     0],\n",
       "         [  101,  2806,  1004,  5053,   102],\n",
       "         [  101,  2204,  2739,   102,     0],\n",
       "         [  101,  2088, 19894,   102,     0],\n",
       "         [  101,  5510,   102,     0,     0],\n",
       "         [  101, 19483,  5755,   102,     0],\n",
       "         [  101,  4024,   102,     0,     0],\n",
       "         [  101,  6881,  2739,   102,     0],\n",
       "         [  101,  7965,  2542,   102,     0],\n",
       "         [  101,  4676,   102,     0,     0],\n",
       "         [  101,  2865,   102,     0,     0],\n",
       "         [  101,  2998,   102,     0,     0],\n",
       "         [  101,  2088,  2739,   102,     0],\n",
       "         [  101,  2495,   102,     0,     0],\n",
       "         [  101,  2840,   102,     0,     0],\n",
       "         [  101,  2806,   102,     0,     0],\n",
       "         [  101, 28586,   102,     0,     0],\n",
       "         [  101,  2833,  1004,  4392,   102],\n",
       "         [  101,  4044,   102,     0,     0],\n",
       "         [  101,  3226,  1004,  2840,   102],\n",
       "         [  101,  2188,  1004,  2542,   102],\n",
       "         [  101,  4038,   102,     0,     0],\n",
       "         [  101,  2304,  5755,   102,     0],\n",
       "         [  101,  2671,   102,     0,     0],\n",
       "         [  101,  3008,   102,     0,     0],\n",
       "         [  101,  2769,   102,     0,     0],\n",
       "         [  101,  4126,   102,     0,     0],\n",
       "         [  101,  4331,   102,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 1, 1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tokenizer.batch_encode_plus(\n",
    "    all_classes_str, return_tensors=\"pt\", add_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataloader\n",
    "batch_size = 24\n",
    "collator = cat.CatCollator(pad_token_id=0)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=collator, shuffle=True)\n",
    "\n",
    "# Classes\n",
    "training_classes_str = set(train_reduced_set['category'])\n",
    "validation_train_classes_str = set(valid_reduced_set['category'])\n",
    "validation_valid_classes_str = set(valid_remainder['category'])\n",
    "\n",
    "assert training_classes_str == validation_train_classes_str\n",
    "\n",
    "all_classes_str = set(all_classes)  # defined above\n",
    "assert training_classes_str.issubset(all_classes_str)\n",
    "assert validation_train_classes_str.issubset(all_classes_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WEDDINGS',\n",
       " 'WELLNESS',\n",
       " 'WOMEN',\n",
       " 'COLLEGE',\n",
       " 'ARTS & CULTURE',\n",
       " 'TRAVEL',\n",
       " 'LATINO VOICES',\n",
       " 'DIVORCE',\n",
       " 'FIFTY',\n",
       " 'THE WORLDPOST',\n",
       " 'GREEN',\n",
       " 'TECH',\n",
       " 'BUSINESS',\n",
       " 'IMPACT',\n",
       " 'STYLE & BEAUTY',\n",
       " 'GOOD NEWS',\n",
       " 'WORLDPOST',\n",
       " 'TASTE',\n",
       " 'QUEER VOICES',\n",
       " 'ENTERTAINMENT',\n",
       " 'WEIRD NEWS',\n",
       " 'HEALTHY LIVING',\n",
       " 'RELIGION',\n",
       " 'MEDIA',\n",
       " 'SPORTS',\n",
       " 'WORLD NEWS',\n",
       " 'EDUCATION',\n",
       " 'ARTS',\n",
       " 'STYLE',\n",
       " 'PARENTING',\n",
       " 'FOOD & DRINK',\n",
       " 'ENVIRONMENT',\n",
       " 'CULTURE & ARTS',\n",
       " 'HOME & LIVING',\n",
       " 'COMEDY',\n",
       " 'BLACK VOICES',\n",
       " 'SCIENCE',\n",
       " 'PARENTS',\n",
       " 'MONEY',\n",
       " 'CRIME',\n",
       " 'POLITICS']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizer.batch_encode_plus of <transformers.tokenization_distilbert.DistilBertTokenizer object at 0x7f458c2b01f0>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tokenizer.batch_encode_plus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_classes_str = list(training_classes_str)\n",
    "training_classes_ids = label_tokenizer.batch_encode_plus(\n",
    "    training_classes_str,\n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True  # should be consistent with the tokenization used in the CatDataset\n",
    ")['input_ids']\n",
    "\n",
    "all_classes_str = list(all_classes_str)\n",
    "all_classes_ids = label_tokenizer.batch_encode_plus(\n",
    "    all_classes_str,\n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True\n",
    ")['input_ids']\n",
    "\n",
    "\n",
    "test_collator_all_labels = CatTestCollator(\n",
    "    possible_labels=all_classes_ids,\n",
    "    pad_token_id=label_tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "\n",
    "test_collator_train_labels = CatTestCollator(\n",
    "    possible_labels=training_classes_ids,\n",
    "    pad_token_id=label_tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "\n",
    "# Validation dataloader for the training classes\n",
    "valid_train_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=test_collator_train_labels,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Validation dataloader for the test classes (zero-shot)\n",
    "valid_valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=test_collator_all_labels,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Validation dataloader for the train classes given all possible classes\n",
    "valid_train_dataloader_but_all = torch.utils.data.DataLoader(\n",
    "    valid_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=test_collator_all_labels,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Validation dataloader for all classes\n",
    "valid_dataloader_full = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=test_collator_all_labels,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train class attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0403, device='cuda:0')\n",
      "tensor(0.0311, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def validate_model_on_dataloader(model, dataloader, device):\n",
    "    if \"CatTestCollator\" not in str(dataloader.collate_fn):\n",
    "        raise RuntimeError(\"Validation or test dataloader should have a CatTestCollator instead of CatCollator\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, c, y in dataloader:\n",
    "            # Note: `c` does not change in CatTestCollator\n",
    "            x, c, y = x.to(device), c.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x, c)\n",
    "\n",
    "            _, preds = logits.max(-1)\n",
    "\n",
    "            n_correct += torch.sum(preds == y).float()\n",
    "            n_total += x.shape[0]\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "_random_text_encoder = transformers.BertModel(transformers.BertConfig(num_hidden_layers=2, intermediate_size=256))\n",
    "_random_label_encoder = transformers.BertModel(transformers.BertConfig(num_hidden_layers=2, intermediate_size=256))\n",
    "_random_model = cat.ClassAttentionModel(_random_text_encoder, _random_label_encoder, hidden_size=768)\n",
    "\n",
    "_acc = validate_model_on_dataloader(_random_model, valid_train_dataloader, device='cuda')\n",
    "print(_acc)\n",
    "\n",
    "_acc = validate_model_on_dataloader(_random_model, valid_valid_dataloader, device='cuda')\n",
    "print(_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def validate_model_per_class_on_dataloader(model, dataloader, device, labels):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        labels: List[str], names of classes, in the same order as in the CatTestCollator.possible_labels\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    label2n_correct = defaultdict(int)\n",
    "    label2n_predicted = defaultdict(int)\n",
    "    label2n_expected = defaultdict(int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, c, y in dataloader:\n",
    "            # Note: `c` does not change in CatTestCollator\n",
    "            x, c, y = x.to(device), c.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x, c)\n",
    "\n",
    "            _, preds = logits.max(-1)\n",
    "\n",
    "            predicted_labels = [labels[i] for i in preds]\n",
    "            expected_labels = [labels[i] for i in y]\n",
    "\n",
    "            for label_pred, label_exp in zip(predicted_labels, expected_labels):\n",
    "                label2n_predicted[label_pred] += 1\n",
    "                label2n_expected[label_exp] += 1\n",
    "                label2n_correct[label_pred] += int(label_pred == label_exp)\n",
    "\n",
    "            n_correct += torch.sum(preds == y).float()\n",
    "            n_total += x.shape[0]\n",
    "\n",
    "    res = {\n",
    "        \"acc\": n_correct / n_total,\n",
    "    }\n",
    "\n",
    "    for label in label2n_expected.keys():\n",
    "        label_str = \"_\".join(label.split(' '))\n",
    "        p = label2n_correct[label] / (label2n_predicted[label] + 1e-7)\n",
    "        r = label2n_correct[label] / (label2n_expected[label] + 1e-7)\n",
    "\n",
    "        res[\"P/\" + label_str] = p\n",
    "        res[\"R/\" + label_str] = r\n",
    "        res[\"F1/\" + label_str] = 2 * (p * r) / (p + r + 1e-7)\n",
    "\n",
    "    model.train()\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': tensor(0.0159, device='cuda:0'), 'P/COMEDY': 0.0, 'R/COMEDY': 0.0, 'F1/COMEDY': 0.0, 'P/PARENTING': 0.0, 'R/PARENTING': 0.0, 'F1/PARENTING': 0.0, 'P/ENTERTAINMENT': 0.0, 'R/ENTERTAINMENT': 0.0, 'F1/ENTERTAINMENT': 0.0, 'P/FOOD_&_DRINK': 0.0, 'R/FOOD_&_DRINK': 0.0, 'F1/FOOD_&_DRINK': 0.0, 'P/WORLDPOST': 0.0, 'R/WORLDPOST': 0.0, 'F1/WORLDPOST': 0.0, 'P/HEALTHY_LIVING': 0.0, 'R/HEALTHY_LIVING': 0.0, 'F1/HEALTHY_LIVING': 0.0, 'P/TRAVEL': 0.0, 'R/TRAVEL': 0.0, 'F1/TRAVEL': 0.0, 'P/WOMEN': 0.0, 'R/WOMEN': 0.0, 'F1/WOMEN': 0.0, 'P/BLACK_VOICES': 0.0, 'R/BLACK_VOICES': 0.0, 'F1/BLACK_VOICES': 0.0, 'P/BUSINESS': 0.0, 'R/BUSINESS': 0.0, 'F1/BUSINESS': 0.0, 'P/WEIRD_NEWS': 0.0, 'R/WEIRD_NEWS': 0.0, 'F1/WEIRD_NEWS': 0.0, 'P/SPORTS': 0.0, 'R/SPORTS': 0.0, 'F1/SPORTS': 0.0, 'P/CRIME': 0.0, 'R/CRIME': 0.0, 'F1/CRIME': 0.0, 'P/IMPACT': 0.0, 'R/IMPACT': 0.0, 'F1/IMPACT': 0.0, 'P/POLITICS': 0.0, 'R/POLITICS': 0.0, 'F1/POLITICS': 0.0, 'P/QUEER_VOICES': 0.0, 'R/QUEER_VOICES': 0.0, 'F1/QUEER_VOICES': 0.0, 'P/WELLNESS': 0.0, 'R/WELLNESS': 0.0, 'F1/WELLNESS': 0.0, 'P/STYLE': 0.0, 'R/STYLE': 0.0, 'F1/STYLE': 0.0, 'P/RELIGION': 0.0, 'R/RELIGION': 0.0, 'F1/RELIGION': 0.0, 'P/STYLE_&_BEAUTY': 0.0, 'R/STYLE_&_BEAUTY': 0.0, 'F1/STYLE_&_BEAUTY': 0.0, 'P/TECH': 0.0, 'R/TECH': 0.0, 'F1/TECH': 0.0, 'P/EDUCATION': 0.0, 'R/EDUCATION': 0.0, 'F1/EDUCATION': 0.0, 'P/LATINO_VOICES': 0.0, 'R/LATINO_VOICES': 0.0, 'F1/LATINO_VOICES': 0.0, 'P/MONEY': 0.0, 'R/MONEY': 0.0, 'F1/MONEY': 0.0, 'P/THE_WORLDPOST': 0.0, 'R/THE_WORLDPOST': 0.0, 'F1/THE_WORLDPOST': 0.0, 'P/DIVORCE': 0.0, 'R/DIVORCE': 0.0, 'F1/DIVORCE': 0.0, 'P/ARTS_&_CULTURE': 0.0, 'R/ARTS_&_CULTURE': 0.0, 'F1/ARTS_&_CULTURE': 0.0, 'P/HOME_&_LIVING': 0.0, 'R/HOME_&_LIVING': 0.0, 'F1/HOME_&_LIVING': 0.0, 'P/GREEN': 0.0, 'R/GREEN': 0.0, 'F1/GREEN': 0.0, 'P/SCIENCE': 0.0, 'R/SCIENCE': 0.0, 'F1/SCIENCE': 0.0, 'P/WORLD_NEWS': 0.0159999999984, 'R/WORLD_NEWS': 0.9999999937499999, 'F1/WORLD_NEWS': 0.03149605988592005, 'P/PARENTS': 0.0, 'R/PARENTS': 0.0, 'F1/PARENTS': 0.0, 'P/TASTE': 0.0, 'R/TASTE': 0.0, 'F1/TASTE': 0.0, 'P/GOOD_NEWS': 0.0, 'R/GOOD_NEWS': 0.0, 'F1/GOOD_NEWS': 0.0, 'P/MEDIA': 0.0, 'R/MEDIA': 0.0, 'F1/MEDIA': 0.0, 'P/WEDDINGS': 0.0, 'R/WEDDINGS': 0.0, 'F1/WEDDINGS': 0.0, 'P/ENVIRONMENT': 0.0, 'R/ENVIRONMENT': 0.0, 'F1/ENVIRONMENT': 0.0, 'P/COLLEGE': 0.0, 'R/COLLEGE': 0.0, 'F1/COLLEGE': 0.0, 'P/CULTURE_&_ARTS': 0.0, 'R/CULTURE_&_ARTS': 0.0, 'F1/CULTURE_&_ARTS': 0.0, 'P/FIFTY': 0.0, 'R/FIFTY': 0.0, 'F1/FIFTY': 0.0, 'P/ARTS': 0.0, 'R/ARTS': 0.0, 'F1/ARTS': 0.0}\n"
     ]
    }
   ],
   "source": [
    "_random_text_encoder = transformers.BertModel(transformers.BertConfig(num_hidden_layers=2, intermediate_size=256))\n",
    "_random_label_encoder = transformers.BertModel(transformers.BertConfig(num_hidden_layers=2, intermediate_size=256))\n",
    "_random_model = cat.ClassAttentionModel(_random_text_encoder, _random_label_encoder, hidden_size=768)\n",
    "\n",
    "_acc = validate_model_per_class_on_dataloader(_random_model, valid_dataloader_full, device='cuda', labels=all_classes_str)\n",
    "print(_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "text_encoder = AutoModel.from_pretrained(MODEL)\n",
    "label_encoder = AutoModel.from_pretrained(MODEL)\n",
    "\n",
    "model = cat.ClassAttentionModel(text_encoder, label_encoder, hidden_size=4096)\n",
    "\n",
    "x = torch.randint(0, 100, size=[3, 5])\n",
    "c = torch.unique(torch.randint(0, 100, size=[7, 1])).unsqueeze(1)\n",
    "\n",
    "out = model(text_input=x, labels_input=c)\n",
    "assert out.shape == (3, 7)\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "parameters = chain(model.txt_encoder.parameters(), model.txt_out.parameters(), model.cls_out.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguitaricet\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dauntless-sunset-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/guitaricet/class_attention\" target=\"_blank\">https://wandb.ai/guitaricet/class_attention</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/guitaricet/class_attention/runs/1rqu7a9e\" target=\"_blank\">https://wandb.ai/guitaricet/class_attention/runs/1rqu7a9e</a><br/>\n",
       "                Run data is saved locally in <code>/home/vlialin/documents/class_attention/notebooks/wandb/run-20210128_173323-1rqu7a9e</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a9559b5fef41f7bb1d6a51e9378a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8ca5c234a148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cat/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_classes_str = ','.join(valid_classes)\n",
    "wandb.init(project='class_attention', tags=['notebooks'], notes=' ', config={\"test_classes\": test_classes_str})\n",
    "wandb.watch(model)\n",
    "\n",
    "\n",
    "for _ in tqdm(range(50)):\n",
    "    for x, c, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        c = c.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x_dict = {'input_ids': x}\n",
    "        c_dict = {'input_ids': c}\n",
    "        logits = model(x_dict, c_dict)\n",
    "\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        _, preds = logits.max(-1)\n",
    "        acc = torch.sum(preds == y).float() / x.shape[0]\n",
    "\n",
    "        wandb.log({\n",
    "            'train_acc': acc,\n",
    "            'loss': loss,\n",
    "        })\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    valid_train_acc = validate_model_on_dataloader(model, valid_train_dataloader, device=device)\n",
    "    valid_valid_acc = validate_model_on_dataloader(model, valid_valid_dataloader, device=device)\n",
    "    valid_train_acc_given_all = validate_model_on_dataloader(model, valid_train_dataloader_but_all, device=device)\n",
    "    valid_acc_per_class = validate_model_per_class_on_dataloader(model, valid_dataloader_full, device=device, labels=all_classes_str)\n",
    "\n",
    "    wandb.log({\n",
    "        'eval/train_classes_acc': valid_train_acc,\n",
    "        'eval/train_classes_given_all_acc': valid_train_acc_given_all,\n",
    "        'eval/valid_classes_acc': valid_valid_acc,\n",
    "        **{f'eval_c/{k}': v for k, v in valid_acc_per_class.items()},\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 58580<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.09MB of 0.09MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/vlialin/documents/class_attention/notebooks/wandb/run-20210127_162852-15al9bae/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/vlialin/documents/class_attention/notebooks/wandb/run-20210127_162852-15al9bae/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc</td><td>0.75</td></tr><tr><td>loss</td><td>0.59033</td></tr><tr><td>_step</td><td>2689</td></tr><tr><td>_runtime</td><td>166</td></tr><tr><td>_timestamp</td><td>1611783098</td></tr><tr><td>validation/train_classes_acc</td><td>0.52755</td></tr><tr><td>validation/train_classes_given_all_acc</td><td>0.52755</td></tr><tr><td>validation/valid_classes_acc</td><td>0.0036</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc</td><td>▁▂▁▃▃▅▄▄▄▂▄▅▅▅▆▅▇▆▅▆▆▅▇▇▆▆▅▇▆▆▇▆█▇▆▇█▆▇▆</td></tr><tr><td>loss</td><td>█▇▇▆▅▄▄▅▄▆▄▄▃▄▄▄▂▂▃▂▂▄▁▁▃▂▄▂▂▃▂▂▂▁▂▁▁▃▁▂</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation/train_classes_acc</td><td>▁█▅█▂</td></tr><tr><td>validation/train_classes_given_all_acc</td><td>▁▆▅█▃</td></tr><tr><td>validation/valid_classes_acc</td><td>█▂▂▁▂</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">light-meadow-20</strong>: <a href=\"https://wandb.ai/guitaricet/class_attention/runs/15al9bae\" target=\"_blank\">https://wandb.ai/guitaricet/class_attention/runs/15al9bae</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat",
   "language": "python",
   "name": "cat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
